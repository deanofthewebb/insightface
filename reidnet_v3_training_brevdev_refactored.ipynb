{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ReidNet V3 Training - InsightFace ArcFace on Custom Dataset\n",
    "\n",
    "PyTorch-based ArcFace training with RecordIO format dataset.\n",
    "\n",
    "**Environment:**\n",
    "- GPU runtime (A100/V100/T4) with CUDA 12.x\n",
    "- ~50GB disk space for dataset\n",
    "- Python 3.8+ (any version)\n",
    "- Root directory: `/home/ubuntu/`\n",
    "\n",
    "**Workflow:**\n",
    "1. Run Step 1 (environment check)\n",
    "2. Run Step 2 (install dependencies) ‚Üí **Restart kernel**\n",
    "3. Run Step 2b and continue sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "environment_check"
   },
   "outputs": [],
   "source": [
    "# üîç STEP 1: ENVIRONMENT CHECK\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {sys.platform}\")\n",
    "\n",
    "# Setup directories\n",
    "WORKDIR = Path(\"/home/ubuntu/insightface_training\")\n",
    "CHECKPOINT_DIR = Path(\"/home/ubuntu/checkpoints/reidnet_v3\")\n",
    "\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÇ Working directory: {WORKDIR}\")\n",
    "print(f\"üíæ Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Check GPU\n",
    "print(\"\\nüéÆ GPU CHECK\")\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# üì¶ STEP 2: INSTALL DEPENDENCIES\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"üì¶ INSTALLING DEPENDENCIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fix PATH for local binaries\n",
    "import os\n",
    "if '/home/ubuntu/.local/bin' not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = f\"/home/ubuntu/.local/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Ensure pip is available in current Python environment\n",
    "print(\"üîß Ensuring pip is available...\")\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"--version\"], capture_output=True)\n",
    "if result.returncode != 0:\n",
    "    print(\"‚ö†Ô∏è  pip not found, bootstrapping...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"ensurepip\", \"--default-pip\"], check=True)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"], check=True)\n",
    "print(\"‚úÖ pip ready\")\n",
    "\n",
    "# Core dependencies\n",
    "!{sys.executable} -m pip install -q numpy boto3 awscli\n",
    "\n",
    "# PyTorch ecosystem (CUDA 12.1 for CUDA 12.x systems)\n",
    "!{sys.executable} -m pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Training dependencies (NO mxnet - PyTorch has native RecordIO reader)\n",
    "!{sys.executable} -m pip install -q tensorboard onnx onnxruntime-gpu easydict opencv-python scikit-image tqdm\n",
    "\n",
    "print(\"\\n‚úÖ Dependencies installed\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: Restart kernel now (Kernel ‚Üí Restart)\")\n",
    "print(\"    Then skip this cell and continue from Step 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_packages"
   },
   "outputs": [],
   "source": [
    "# üìã STEP 2b: VERIFY PACKAGES (AFTER KERNEL RESTART)\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Fix PATH\n",
    "if '/home/ubuntu/.local/bin' not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = f\"/home/ubuntu/.local/bin:{os.environ['PATH']}\"\n",
    "\n",
    "print(\"üìã PACKAGE VERSIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  CUDA not available - training will be very slow!\")\n",
    "\n",
    "# Re-establish paths from Step 1\n",
    "WORKDIR = Path(\"/home/ubuntu/insightface_training\")\n",
    "CHECKPOINT_DIR = Path(\"/home/ubuntu/checkpoints/reidnet_v3\")\n",
    "print(f\"\\n‚úÖ Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# üì• STEP 3: CLONE INSIGHTFACE REPOSITORY\n",
    "import os\n",
    "\n",
    "repo_path = WORKDIR / \"insightface\"\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', '')\n",
    "GITHUB_USER = os.getenv('GITHUB_USER', 'deanofthewebb')\n",
    "BRANCH = \"main\"\n",
    "\n",
    "if GITHUB_TOKEN:\n",
    "    REPO_URL = f\"https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/insightface.git\"\n",
    "else:\n",
    "    REPO_URL = f\"https://github.com/{GITHUB_USER}/insightface.git\"\n",
    "\n",
    "if not repo_path.exists():\n",
    "    print(f\"üì• Cloning InsightFace repository...\")\n",
    "    !git clone --depth 1 --branch {BRANCH} {REPO_URL} {repo_path}\n",
    "    print(\"‚úÖ Repository cloned\")\n",
    "else:\n",
    "    print(\"üìÅ Repository exists, pulling latest changes...\")\n",
    "    !cd {repo_path} && git pull origin {BRANCH}\n",
    "    print(\"‚úÖ Repository updated\")\n",
    "\n",
    "# Navigate to training directory\n",
    "training_dir = repo_path / \"recognition\" / \"arcface_torch\"\n",
    "os.chdir(training_dir)\n",
    "print(f\"\\nüìç Working in: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aws_credentials"
   },
   "outputs": [],
   "source": [
    "# üîë STEP 4: CONFIGURE AWS CREDENTIALS\n",
    "import os\n",
    "import pathlib\n",
    "import boto3\n",
    "\n",
    "print(\"üîë CONFIGURING AWS CREDENTIALS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read credentials from environment\n",
    "AK = os.getenv(\"AWS_ACCESS_KEY_ID\", \"\")\n",
    "SK = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"\")\n",
    "REGION = os.getenv(\"AWS_DEFAULT_REGION\", \"us-east-2\")\n",
    "\n",
    "if not AK or not SK:\n",
    "    raise ValueError(\"AWS credentials not found. Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables.\")\n",
    "\n",
    "# Clear stale session tokens (keep credentials)\n",
    "for k in [\"AWS_SESSION_TOKEN\", \"AWS_SECURITY_TOKEN\", \"AWS_PROFILE\"]:\n",
    "    os.environ.pop(k, None)\n",
    "\n",
    "# Write AWS config\n",
    "aws_dir = pathlib.Path.home() / \".aws\"\n",
    "aws_dir.mkdir(parents=True, exist_ok=True)\n",
    "(aws_dir / \"credentials\").write_text(\n",
    "    f\"[default]\\naws_access_key_id={AK}\\naws_secret_access_key={SK}\\n\"\n",
    ")\n",
    "(aws_dir / \"config\").write_text(\n",
    "    f\"[default]\\nregion={REGION}\\noutput=json\\n\"\n",
    ")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AK\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = SK\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = REGION\n",
    "\n",
    "# Verify credentials\n",
    "try:\n",
    "    sts = boto3.client(\"sts\", region_name=REGION)\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"\\n‚úÖ AWS credentials verified\")\n",
    "    print(f\"   Account: {identity['Account']}\")\n",
    "    print(f\"   User: {identity['Arn']}\")\n",
    "    \n",
    "    # Check disk space\n",
    "    print(\"\\nüìä Disk Space:\")\n",
    "    !df -h /home/ubuntu | head -2\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå AWS verification failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_dataset"
   },
   "outputs": [],
   "source": [
    "# üì• STEP 5: DOWNLOAD DATASET FROM S3\n",
    "import subprocess\n",
    "import boto3\n",
    "\n",
    "print(\"üì• DOWNLOADING REIDNET V3 DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset configuration\n",
    "BUCKET = \"data-labeling.livereachmedia.com\"\n",
    "PREFIX = \"datasets/reidnet_v3/rekognition_set/\"\n",
    "DATASET_DIR = WORKDIR / \"datasets\" / \"reidnet_v3_rec\"\n",
    "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Required files for RecordIO format (PyTorch reads natively)\n",
    "required_files = [\"train.rec\", \"train.idx\", \"property\"]\n",
    "\n",
    "print(f\"\\nSource: s3://{BUCKET}/{PREFIX}\")\n",
    "print(f\"Destination: {DATASET_DIR}\\n\")\n",
    "\n",
    "s3 = boto3.client(\"s3\", region_name=REGION)\n",
    "\n",
    "for filename in required_files:\n",
    "    s3_key = f\"{PREFIX}{filename}\"\n",
    "    local_path = DATASET_DIR / filename\n",
    "    \n",
    "    if local_path.exists():\n",
    "        print(f\"‚è≠Ô∏è  {filename} already exists\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Get file size\n",
    "        head = s3.head_object(Bucket=BUCKET, Key=s3_key)\n",
    "        size_mb = head[\"ContentLength\"] / 1e6\n",
    "        print(f\"üì¶ Downloading {filename} ({size_mb:.1f} MB)...\")\n",
    "        \n",
    "        # Download\n",
    "        s3.download_file(BUCKET, s3_key, str(local_path))\n",
    "        print(f\"‚úÖ {filename} downloaded\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download {filename}: {e}\\n\")\n",
    "        raise\n",
    "\n",
    "# Read dataset statistics from property file\n",
    "property_file = DATASET_DIR / \"property\"\n",
    "if property_file.exists():\n",
    "    lines = property_file.read_text().strip().split(\"\\n\")\n",
    "    num_classes = int(lines[0].split(\",\")[0])\n",
    "    num_images = int(lines[1])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä DATASET STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Identities: {num_classes:,}\")\n",
    "    print(f\"Images: {num_images:,}\")\n",
    "    print(f\"Avg images/identity: {num_images/num_classes:.1f}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Dataset property file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_pretrained"
   },
   "outputs": [],
   "source": [
    "# üì• STEP 6: DOWNLOAD PRETRAINED MODEL\n",
    "print(\"üì• DOWNLOADING PRETRAINED ONNX MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pretrained_dir = WORKDIR / \"pretrained_models\"\n",
    "pretrained_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NVR production ONNX backbone (LResNet100E-IR ArcFace)\n",
    "S3_MODEL_PATH = \"s3://data-labeling.livereachmedia.com/datasets/face_rec/nvr.prod.v7.facerec.backbone.onnx\"\n",
    "model_name = \"nvr.prod.v7.facerec.backbone.onnx\"\n",
    "local_model = pretrained_dir / model_name\n",
    "\n",
    "if local_model.exists():\n",
    "    print(f\"\\n‚è≠Ô∏è  Model already exists: {model_name}\")\n",
    "    ONNX_BACKBONE = str(local_model)\n",
    "else:\n",
    "    try:\n",
    "        print(f\"\\nüì¶ Downloading {model_name}...\")\n",
    "        !aws s3 cp {S3_MODEL_PATH} {local_model} --only-show-errors\n",
    "        \n",
    "        size_mb = local_model.stat().st_size / 1e6\n",
    "        print(f\"‚úÖ Downloaded ({size_mb:.1f} MB)\")\n",
    "        ONNX_BACKBONE = str(local_model)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Failed to download ONNX model: {e}\")\n",
    "        print(\"   Training will start with random initialization\")\n",
    "        ONNX_BACKBONE = None\n",
    "\n",
    "print(f\"\\nüìç ONNX backbone: {ONNX_BACKBONE or 'None (random init)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_config"
   },
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è STEP 7: CREATE TRAINING CONFIG\n",
    "print(\"‚öôÔ∏è CREATING TRAINING CONFIG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Read dataset statistics\n",
    "property_file = DATASET_DIR / \"property\"\n",
    "lines = property_file.read_text().strip().split(\"\\n\")\n",
    "num_classes = int(lines[0].split(\",\")[0])\n",
    "num_images = int(lines[1])\n",
    "\n",
    "print(f\"\\nDataset: {num_classes:,} identities, {num_images:,} images\")\n",
    "\n",
    "# Create config\n",
    "config_content = f'''# ReidNet V3 Fine-tuning Configuration\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = edict()\n",
    "\n",
    "# Network architecture\n",
    "config.network = \"r100\"  # ResNet100 backbone\n",
    "config.embedding_size = 512\n",
    "config.margin_list = (1.0, 0.5, 0.0)  # ArcFace (m, s, a)\n",
    "config.interclass_filtering_threshold = 0.0\n",
    "\n",
    "# Output directory\n",
    "config.output = \"{CHECKPOINT_DIR / 'work_dirs'}\"\n",
    "config.resume = False\n",
    "\n",
    "# Dataset (RecordIO format)\n",
    "config.rec = \"{DATASET_DIR}\"\n",
    "config.num_classes = {num_classes}\n",
    "config.num_image = {num_images}\n",
    "config.num_workers = 8\n",
    "config.dali = False  # Set True if NVIDIA DALI available\n",
    "\n",
    "# Training hyperparameters\n",
    "config.batch_size = 128  # Adjust based on GPU: A100=512, V100=128, T4=64\n",
    "config.lr = 0.01  # Conservative for fine-tuning\n",
    "config.optimizer = \"sgd\"\n",
    "config.momentum = 0.9\n",
    "config.weight_decay = 5e-4\n",
    "config.sample_rate = 1.0\n",
    "config.fp16 = True  # Mixed precision training\n",
    "\n",
    "# Training schedule\n",
    "config.num_epoch = 24\n",
    "config.warmup_epoch = 0  # Skip warmup for fine-tuning\n",
    "\n",
    "# Logging and checkpointing\n",
    "config.verbose = 2000\n",
    "config.frequent = 20\n",
    "config.save_all_states = True\n",
    "config.save_interval = 20000\n",
    "config.gradient_acc = 1\n",
    "\n",
    "# Evaluation\n",
    "config.val_targets = []  # Add validation datasets if available\n",
    "\n",
    "config.seed = 2048\n",
    "'''\n",
    "\n",
    "# Write config\n",
    "config_dir = training_dir / \"configs\"\n",
    "config_dir.mkdir(exist_ok=True)\n",
    "config_file = config_dir / \"reidnet_v3_finetune.py\"\n",
    "config_file.write_text(config_content)\n",
    "\n",
    "print(f\"\\n‚úÖ Config saved: {config_file}\")\n",
    "print(\"\\nüìã Training Configuration:\")\n",
    "print(f\"   Identities: {num_classes:,}\")\n",
    "print(f\"   Images: {num_images:,}\")\n",
    "print(f\"   Batch size: 128 per GPU\")\n",
    "print(f\"   Epochs: 24\")\n",
    "print(f\"   Mixed precision: Enabled\")\n",
    "print(f\"   Pretrained: {'Yes' if PRETRAINED_MODEL else 'No (from scratch)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "# üöÄ STEP 8: START TRAINING\n",
    "import os\n",
    "\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.chdir(training_dir)\n",
    "\n",
    "# Build command\n",
    "cmd = [\"python\", \"train_v3.py\", \"configs/reidnet_v3_finetune.py\"]\n",
    "\n",
    "# Add ONNX backbone if available\n",
    "if ONNX_BACKBONE and Path(ONNX_BACKBONE).exists():\n",
    "    cmd.extend([\"--onnx-backbone\", ONNX_BACKBONE])\n",
    "    print(f\"\\nüì¶ Using ONNX backbone:\\n   {ONNX_BACKBONE}\")\n",
    "    print(f\"   Architecture: LResNet100E-IR (512-D embeddings)\")\n",
    "else:\n",
    "    print(\"\\nüî® Training from random initialization (no pretrained backbone)\")\n",
    "\n",
    "print(f\"\\nüíª Command: {' '.join(cmd)}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ TRAINING STARTED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÇ Checkpoints: {CHECKPOINT_DIR / 'work_dirs'}\")\n",
    "print(\"\\nTo monitor: Open TensorBoard in next cell\")\n",
    "print(\"To stop: Runtime ‚Üí Interrupt\\n\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Execute training\n",
    "!{' '.join(cmd)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monitor_training"
   },
   "outputs": [],
   "source": [
    "# üìä STEP 9: MONITOR TRAINING (RUN IN PARALLEL)\n",
    "print(\"üìä LAUNCHING TENSORBOARD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "%load_ext tensorboard\n",
    "tensorboard_dir = CHECKPOINT_DIR / \"work_dirs\" / \"logs\"\n",
    "print(f\"\\nüìà Log directory: {tensorboard_dir}\\n\")\n",
    "\n",
    "%tensorboard --logdir {tensorboard_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_model"
   },
   "outputs": [],
   "source": [
    "# üì§ STEP 10: EXPORT CHECKPOINTS TO S3 (AFTER TRAINING)\n",
    "print(\"üì§ EXPORTING CHECKPOINTS TO S3\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "work_dir = CHECKPOINT_DIR / \"work_dirs\"\n",
    "checkpoints = sorted(work_dir.glob(\"**/backbone.pth\"), key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"\\n‚úÖ Found {len(checkpoints)} checkpoint(s)\\n\")\n",
    "    \n",
    "    # Upload all checkpoints to S3\n",
    "    s3_base = \"s3://data-labeling.livereachmedia.com/models/reidnet_v3/checkpoints/\"\n",
    "    \n",
    "    for ckpt in checkpoints:\n",
    "        size_mb = ckpt.stat().st_size / 1e6\n",
    "        s3_path = f\"{s3_base}{ckpt.parent.name}_{ckpt.name}\"\n",
    "        \n",
    "        print(f\"üì¶ Uploading {ckpt.name} ({size_mb:.1f} MB)...\")\n",
    "        !aws s3 cp {ckpt} {s3_path} --only-show-errors\n",
    "        print(f\"‚úÖ Uploaded to {s3_path}\\n\")\n",
    "    \n",
    "    # Upload latest checkpoint with special name\n",
    "    latest = checkpoints[-1]\n",
    "    s3_latest = f\"{s3_base}reidnet_v3_latest.pth\"\n",
    "    print(f\"üì¶ Uploading latest checkpoint as reidnet_v3_latest.pth...\")\n",
    "    !aws s3 cp {latest} {s3_latest} --only-show-errors\n",
    "    print(f\"‚úÖ Latest checkpoint: {s3_latest}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ ALL CHECKPOINTS UPLOADED TO S3\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No checkpoints found. Training may still be in progress.\")\n",
    "    print(f\"   Check: {work_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "Reduce `batch_size` in config:\n",
    "- A100 (80GB): 512\n",
    "- A100 (40GB): 256\n",
    "- V100 (32GB): 128\n",
    "- V100 (16GB): 64\n",
    "- T4 (16GB): 32-64\n",
    "\n",
    "Or disable mixed precision: `config.fp16 = False`\n",
    "\n",
    "### Slow Training\n",
    "- Increase `num_workers` (try 8-16)\n",
    "- Enable DALI if available: `config.dali = True`\n",
    "- Check if dataset is on SSD\n",
    "\n",
    "### Dataset Format\n",
    "RecordIO format requires:\n",
    "- `train.rec` - binary record file\n",
    "- `train.idx` - index file\n",
    "- `property` - metadata (2 lines: num_classes,112,112 and num_images)\n",
    "\n",
    "**Note**: PyTorch ArcFace has native RecordIO reader - no MXNet required!\n",
    "\n",
    "### CUDA Errors\n",
    "```bash\n",
    "# Check CUDA installation\n",
    "!nvidia-smi\n",
    "!nvcc --version\n",
    "\n",
    "# Reinstall PyTorch with correct CUDA version\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "```\n",
    "\n",
    "## üìñ References\n",
    "\n",
    "- [InsightFace GitHub](https://github.com/deepinsight/insightface)\n",
    "- [ArcFace Paper](https://arxiv.org/abs/1801.07698)\n",
    "- [PyTorch ArcFace Docs](https://github.com/deepinsight/insightface/tree/master/recognition/arcface_torch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
